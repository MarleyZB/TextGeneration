{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Universidad Autónoma de Chihuahua - Facultad de Ingeniería\n",
        "\n",
        "---\n",
        "\"*Shakespeare-like - Text generation*\"\n",
        "\n",
        "---\n",
        ">Data Science\n",
        "\n",
        ">Jesús Roberto López Santillán\n",
        "\n",
        "**338900 - Marley Zaragoza Balderrama**\n",
        "\n",
        "---\n",
        "24/05/2023\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "eUYxf8JMrjdE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAH8EZkJTAgE"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQjyKTZITAgG"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "if IS_COLAB:\n",
        "    %pip install -q -U tensorflow-addons\n",
        "    %pip install -q -U transformers\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "    if IS_KAGGLE:\n",
        "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"nlp\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbepLTRXTAgK"
      },
      "source": [
        "# Char-RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drSvQF47TAgL"
      },
      "source": [
        "## Splitting a sequence into batches of shuffled windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "rsCUHooRTAgM",
        "outputId": "b1f23ad3-9f0e-4b3e-eaed-e39d3964fb49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "____________________ Batch 0 \n",
            "X_batch\n",
            "[[6 7 8 9]\n",
            " [2 3 4 5]\n",
            " [4 5 6 7]]\n",
            "===== \n",
            "Y_batch\n",
            "[[ 7  8  9 10]\n",
            " [ 3  4  5  6]\n",
            " [ 5  6  7  8]]\n",
            "____________________ Batch 1 \n",
            "X_batch\n",
            "[[ 0  1  2  3]\n",
            " [ 8  9 10 11]\n",
            " [10 11 12 13]]\n",
            "===== \n",
            "Y_batch\n",
            "[[ 1  2  3  4]\n",
            " [ 9 10 11 12]\n",
            " [11 12 13 14]]\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "n_steps = 5\n",
        "dataset = tf.data.Dataset.from_tensor_slices(tf.range(15))\n",
        "dataset = dataset.window(n_steps, shift=2, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(n_steps))\n",
        "dataset = dataset.shuffle(10).map(lambda window: (window[:-1], window[1:]))\n",
        "dataset = dataset.batch(3).prefetch(1)\n",
        "for index, (X_batch, Y_batch) in enumerate(dataset):\n",
        "    print(\"_\" * 20, \"Batch\", index, \"\\nX_batch\")\n",
        "    print(X_batch.numpy())\n",
        "    print(\"=\" * 5, \"\\nY_batch\")\n",
        "    print(Y_batch.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFxCotpoTAgN"
      },
      "source": [
        "## Loading the Data and Preparing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vD2Gb7aKTAgO"
      },
      "outputs": [],
      "source": [
        "filepath = \"Christopher_Nolan_Scripts.txt\"\n",
        "with open(filepath) as f:\n",
        "    cns = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llqZqpeDTAgO",
        "outputId": "e6d309ad-9d29-4aa3-9e0b-9a1a3554b7d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE FOLLOWING\n",
            "Written by\n",
            "Christopher Nolan\n",
            "T H E F O L L O W I N G\n",
            "EXT. CROWDED LONDON STREET - DAY\n",
            "An endless stream of pedestrians crossing the fr\n"
          ]
        }
      ],
      "source": [
        "print(cns[:148])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5MpFanPTAgP",
        "outputId": "f77b5f25-bdab-4f72-ce99-9d96d99b1b74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n !\"%&\\'()*,-./0123456789:;=?[\\\\]`abcdefghijklmnopqrstuvwxyz~£¯éû–‘’“”…−'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "\"\".join(sorted(set(cns.lower())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgP2bg2aTAgP"
      },
      "outputs": [],
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(cns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS5jw-9JTAgQ",
        "outputId": "b79868f8-a819-430d-dc13-8712aaf94978",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[23, 8, 9, 7, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences([\"First\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4dvJfvWTAgQ",
        "outputId": "3ad68403-3784-440c-8e3b-8d6a97b9ea8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['y n r i t']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geDkS_pPTAgR",
        "outputId": "4d56c7c1-6bbc-4525-e63d-75a61aed088b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1150954"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "max_id = len(tokenizer.word_index) # number of distinct characters\n",
        "dataset_size = tokenizer.document_count # total number of characters\n",
        "dataset_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcjNhvHcTAgR"
      },
      "outputs": [],
      "source": [
        "[encoded] = np.array(tokenizer.texts_to_sequences([cns])) - 1\n",
        "train_size = dataset_size * 90 // 100\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__yiPkPxTAgS"
      },
      "outputs": [],
      "source": [
        "n_steps = 100\n",
        "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
        "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FY006OVTAgT"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuXpDUcdTAgT"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQhQVIp2TAgT"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4JHZUxTTAgU"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yb_ZBDErTAgU"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6302ykvTAgV",
        "outputId": "f9b86493-12ba-4e2e-9d3e-b976c83e1c5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 100, 70) (32, 100)\n"
          ]
        }
      ],
      "source": [
        "for X_batch, Y_batch in dataset.take(1):\n",
        "    print(X_batch.shape, Y_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKxZEv3dTAgV"
      },
      "source": [
        "## Creating and Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrhAPzq8TAgW",
        "outputId": "0720a6b1-ae12-4454-a778-80393495c490",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32368/32368 [==============================] - 487s 15ms/step - loss: 1.4005\n",
            "Epoch 2/20\n",
            "32368/32368 [==============================] - 502s 15ms/step - loss: 1.3109\n",
            "Epoch 3/20\n",
            "32368/32368 [==============================] - 504s 16ms/step - loss: 1.2882\n",
            "Epoch 4/20\n",
            "32368/32368 [==============================] - 488s 15ms/step - loss: 1.2756\n",
            "Epoch 5/20\n",
            "32368/32368 [==============================] - 483s 15ms/step - loss: 1.2678\n",
            "Epoch 6/20\n",
            "32368/32368 [==============================] - 479s 15ms/step - loss: 1.2618\n",
            "Epoch 7/20\n",
            "32368/32368 [==============================] - 496s 15ms/step - loss: 1.2576\n",
            "Epoch 8/20\n",
            "32368/32368 [==============================] - 481s 15ms/step - loss: 1.2541\n",
            "Epoch 9/20\n",
            "32368/32368 [==============================] - 496s 15ms/step - loss: 1.2523\n",
            "Epoch 10/20\n",
            "32368/32368 [==============================] - 504s 16ms/step - loss: 1.2489\n",
            "Epoch 11/20\n",
            "32368/32368 [==============================] - 522s 16ms/step - loss: 1.2473\n",
            "Epoch 12/20\n",
            "32368/32368 [==============================] - 515s 16ms/step - loss: 1.2450\n",
            "Epoch 13/20\n",
            "32368/32368 [==============================] - 509s 16ms/step - loss: 1.2442\n",
            "Epoch 14/20\n",
            "32368/32368 [==============================] - 498s 15ms/step - loss: 1.2429\n",
            "Epoch 15/20\n",
            "32368/32368 [==============================] - 516s 16ms/step - loss: 1.2421\n",
            "Epoch 16/20\n",
            "32368/32368 [==============================] - 499s 15ms/step - loss: 1.2413\n",
            "Epoch 17/20\n",
            "32368/32368 [==============================] - 496s 15ms/step - loss: 1.2400\n",
            "Epoch 18/20\n",
            "32368/32368 [==============================] - 492s 15ms/step - loss: 1.2395\n",
            "Epoch 19/20\n",
            "32368/32368 [==============================] - 516s 16ms/step - loss: 1.2383\n",
            "Epoch 20/20\n",
            "32368/32368 [==============================] - 526s 16ms/step - loss: 1.2374\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
        "                     #dropout=0.2, recurrent_dropout=0.2),\n",
        "                     dropout=0.2),\n",
        "    keras.layers.GRU(128, return_sequences=True,\n",
        "                     #dropout=0.2, recurrent_dropout=0.2),\n",
        "                     dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "history = model.fit(dataset, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN7VTYBuTAgX"
      },
      "source": [
        "## Using the Model to Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAWsdAqjTAgX"
      },
      "outputs": [],
      "source": [
        "def preprocess(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "    return tf.one_hot(X, max_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdpK-X4aTAgY",
        "outputId": "aee31324-a848-40c1-ec36-59da86bc7011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'u'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "X_new = preprocess([\"How are yo\"])\n",
        "#Y_pred = model.predict_classes(X_new)\n",
        "Y_pred = np.argmax(model(X_new), axis=-1)\n",
        "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 1st sentence, last char"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDadzKQETAga",
        "outputId": "e13bb07c-ff5e-4b14-d73c-da2d636f749a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "        2, 0, 0, 1, 1, 1, 0, 0, 1, 2, 0, 0, 1, 1, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "tf.random.categorical([[np.log(0.5), np.log(0.4), np.log(0.1)]], num_samples=40).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zl-Tn1fOTAgb"
      },
      "outputs": [],
      "source": [
        "def next_char(text, temperature=1):\n",
        "    X_new = preprocess([text])\n",
        "    y_proba = model(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeSXXtjaTAgb",
        "outputId": "005de838-e5eb-462b-a4d0-37f6ac3aae3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'u'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "next_char(\"How are yo\", temperature=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNEoVlBMTAgc"
      },
      "outputs": [],
      "source": [
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrIK6dI_TAgw",
        "outputId": "eee49ad9-e90c-465b-fba2-38ba8a863ceb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mother box.\n",
            "\n",
            "the amazons are a project on the t\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "print(complete_text(\"t\", temperature=0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eUNpIyATAgx",
        "outputId": "9f662345-d377-4fdf-c93c-669bd46ec413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to,\n",
            "both\n",
            "down from been a\n",
            "wartral inols.\n",
            "int. cockp\n"
          ]
        }
      ],
      "source": [
        "print(complete_text(\"t\", temperature=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83rZov5TTAgy",
        "outputId": "8dbb7af3-14d4-452b-be48-e9f330a67898",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfendou.\n",
            "\n",
            "labs) towyr!\n",
            "\n",
            "yell.\"\n",
            "\n",
            "whts snapricr’s alu\n"
          ]
        }
      ],
      "source": [
        "print(complete_text(\"t\", temperature=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-zgi3k1TAgy"
      },
      "source": [
        "## Stateful RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EQ6ZDgwTAgy"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0lTmCCiTAgz"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "dataset = dataset.batch(1)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "dataset = dataset.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuOpnxSvTAgz"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
        "datasets = []\n",
        "for encoded_part in encoded_parts:\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
        "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "    datasets.append(dataset)\n",
        "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
        "dataset = dataset.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ntgy_r7iTAg0"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
        "                     #dropout=0.2, recurrent_dropout=0.2,\n",
        "                     dropout=0.2,\n",
        "                     batch_input_shape=[batch_size, None, max_id]),\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
        "                     #dropout=0.2, recurrent_dropout=0.2),\n",
        "                     dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIF0UayHTAg1"
      },
      "outputs": [],
      "source": [
        "class ResetStatesCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs):\n",
        "        self.model.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGf_WWAMTAg1",
        "outputId": "c329ed47-7666-4965-fe5c-2f2e18fda726",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "323/323 [==============================] - 10s 18ms/step - loss: 2.5988\n",
            "Epoch 2/50\n",
            "323/323 [==============================] - 8s 24ms/step - loss: 2.1451\n",
            "Epoch 3/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 1.9876\n",
            "Epoch 4/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 1.8964\n",
            "Epoch 5/50\n",
            "323/323 [==============================] - 8s 24ms/step - loss: 1.8337\n",
            "Epoch 6/50\n",
            "323/323 [==============================] - 6s 18ms/step - loss: 1.7915\n",
            "Epoch 7/50\n",
            "323/323 [==============================] - 7s 23ms/step - loss: 1.7590\n",
            "Epoch 8/50\n",
            "323/323 [==============================] - 5s 17ms/step - loss: 1.7317\n",
            "Epoch 9/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 1.7108\n",
            "Epoch 10/50\n",
            "323/323 [==============================] - 7s 22ms/step - loss: 1.6941\n",
            "Epoch 11/50\n",
            "323/323 [==============================] - 6s 18ms/step - loss: 1.6792\n",
            "Epoch 12/50\n",
            "323/323 [==============================] - 8s 24ms/step - loss: 1.6642\n",
            "Epoch 13/50\n",
            "323/323 [==============================] - 10s 30ms/step - loss: 1.6520\n",
            "Epoch 14/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 1.6441\n",
            "Epoch 15/50\n",
            "323/323 [==============================] - 7s 20ms/step - loss: 1.6326\n",
            "Epoch 16/50\n",
            "323/323 [==============================] - 6s 20ms/step - loss: 1.6242\n",
            "Epoch 17/50\n",
            "323/323 [==============================] - 8s 25ms/step - loss: 1.6157\n",
            "Epoch 18/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 1.6089\n",
            "Epoch 19/50\n",
            "323/323 [==============================] - 7s 23ms/step - loss: 1.5994\n",
            "Epoch 20/50\n",
            "323/323 [==============================] - 5s 17ms/step - loss: 1.5943\n",
            "Epoch 21/50\n",
            "323/323 [==============================] - 8s 25ms/step - loss: 1.5896\n",
            "Epoch 22/50\n",
            "323/323 [==============================] - 5s 17ms/step - loss: 1.5822\n",
            "Epoch 23/50\n",
            "323/323 [==============================] - 8s 24ms/step - loss: 1.5778\n",
            "Epoch 24/50\n",
            "323/323 [==============================] - 5s 17ms/step - loss: 1.5727\n",
            "Epoch 25/50\n",
            "323/323 [==============================] - 6s 19ms/step - loss: 1.5676\n",
            "Epoch 26/50\n",
            "323/323 [==============================] - 7s 21ms/step - loss: 1.5644\n",
            "Epoch 27/50\n",
            "323/323 [==============================] - 6s 20ms/step - loss: 1.5605\n",
            "Epoch 28/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 1.5537\n",
            "Epoch 29/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 1.5522\n",
            "Epoch 30/50\n",
            "323/323 [==============================] - 6s 18ms/step - loss: 1.5493\n",
            "Epoch 31/50\n",
            "323/323 [==============================] - 7s 23ms/step - loss: 1.5470\n",
            "Epoch 32/50\n",
            "323/323 [==============================] - 7s 20ms/step - loss: 1.5407\n",
            "Epoch 33/50\n",
            "323/323 [==============================] - 5s 17ms/step - loss: 1.5370\n",
            "Epoch 34/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 1.5342\n",
            "Epoch 35/50\n",
            "323/323 [==============================] - 7s 21ms/step - loss: 1.5332\n",
            "Epoch 36/50\n",
            "323/323 [==============================] - 5s 17ms/step - loss: 1.5288\n",
            "Epoch 37/50\n",
            "323/323 [==============================] - 8s 23ms/step - loss: 1.5266\n",
            "Epoch 38/50\n",
            "323/323 [==============================] - 5s 17ms/step - loss: 1.5285\n",
            "Epoch 39/50\n",
            "323/323 [==============================] - 7s 22ms/step - loss: 1.5268\n",
            "Epoch 40/50\n",
            "323/323 [==============================] - 6s 18ms/step - loss: 1.5196\n",
            "Epoch 41/50\n",
            "323/323 [==============================] - 7s 23ms/step - loss: 1.5185\n",
            "Epoch 42/50\n",
            "323/323 [==============================] - 6s 19ms/step - loss: 1.5163\n",
            "Epoch 43/50\n",
            "323/323 [==============================] - 5s 17ms/step - loss: 1.5143\n",
            "Epoch 44/50\n",
            "323/323 [==============================] - 7s 21ms/step - loss: 1.5117\n",
            "Epoch 45/50\n",
            "323/323 [==============================] - 6s 17ms/step - loss: 1.5080\n",
            "Epoch 46/50\n",
            "323/323 [==============================] - 9s 28ms/step - loss: 1.5066\n",
            "Epoch 47/50\n",
            "323/323 [==============================] - 6s 19ms/step - loss: 1.5044\n",
            "Epoch 48/50\n",
            "323/323 [==============================] - 7s 23ms/step - loss: 1.5043\n",
            "Epoch 49/50\n",
            "323/323 [==============================] - 6s 18ms/step - loss: 1.5012\n",
            "Epoch 50/50\n",
            "323/323 [==============================] - 7s 23ms/step - loss: 1.5006\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "history = model.fit(dataset, epochs=50,\n",
        "                    callbacks=[ResetStatesCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VbTwP28TAg2"
      },
      "outputs": [],
      "source": [
        "stateless_model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\n",
        "    keras.layers.GRU(128, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeROi33CTAg3"
      },
      "outputs": [],
      "source": [
        "stateless_model.build(tf.TensorShape([None, None, max_id]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txXbB7V0TAg3"
      },
      "outputs": [],
      "source": [
        "stateless_model.set_weights(model.get_weights())\n",
        "model = stateless_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oB7hpo6ZTAg4",
        "outputId": "38a83390-dd4c-4452-c6bb-83dcb533b16f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t know dind his on\n",
            "a smile give street.\n",
            "\n",
            "what it’s \n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "print(complete_text(\"t\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}